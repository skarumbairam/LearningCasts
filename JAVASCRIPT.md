# ================ Javascript ================

## What is a call stack?

The call stack is a mechanism in JavaScript where functions and code blocks are executed sequentially, one line at a time. It can be thought of as the interpreter's process in a web browser. The call stack is a component of the JavaScript engineâ€”such as the V8 engine in Chrome or SpiderMonkey in Firefox. It operates using a Last In, First Out (LIFO) data structure, meaning that the most recently added function or code block is the first to be executed.

## What is Hoisting?

Hoisting is a behavior in JavaScript that allows variables and functions to be accessed before they are initialized. This feature is unique to JavaScript and is not typically found in other programming languages.

Before JavaScript code is executed, two phases take place: the Memory Phase and the Code Execution Phase. During the Memory Phase, all variables and functions are moved to the top of the program. Variables are assigned a placeholder value of "undefined," while functions are stored as key-value pairs, with the function name as the key and its declaration as the value.

After this, the Code Execution Phase begins, and the code is executed line by line inside the call stack.

## What are Scopes in Javascript?

In JavaScript, scope refers to the **context** in which variables, functions, and objects are accessible or visible. It determines where these elements can be referenced or used within the code. Essentially, scope defines the boundaries of where a variable or function can be accessed and modified.

There are a few types of scope in JavaScript:

**Global Scope:**

Variables declared outside of any function are in the global scope. They can be accessed from anywhere in the code, including inside functions.
In a browser, global variables are typically added to the window object.

**Function Scope:**

Variables declared inside a function are only accessible within that function. They are not visible outside of it. This is also called local scope.
Every time a function is invoked, a new scope is created.

**Block Scope:**

Variables declared with let or const are scoped to the block (usually inside curly braces {}) where they are defined, rather than to the entire function.
For example, a variable declared within an if or for block will not be accessible outside of that block.

**Lexical Scope:**

JavaScript uses lexical scoping, meaning the scope of a variable is determined by where it is declared in the source code, not where it is called from. Inner functions have access to variables in their outer (enclosing) scopes.
```
let x = 10; // Global scope

function myFunction() {
  let y = 20; // Function scope
  if (true) {
    let z = 30; // Block scope
    console.log(x, y, z); // Accessible
  }
  console.log(x, y); // Accessible
  console.log(z); // Error: z is not defined
}

myFunction();
console.log(x); // Accessible
console.log(y); // Error: y is not defined

```

## What is Closure in Javascript?

A closure is a function that is bundled with its surrounding (or lexical) environment. 
In other words, a closure allows an inner function to access variables from its outer function, even after the outer function has finished executing. 
This means the inner function "remembers" its lexical environment, enabling it to use those variables later, even if it's executed in a different context or scope.

``` 
function outerFunction(outerVariable) {
  // outerVariable is part of the outer function's lexical environment
  return function innerFunction(innerVariable) {
    // innerFunction has access to outerVariable because of closure
    console.log("Outer Variable: " + outerVariable);
    console.log("Inner Variable: " + innerVariable);
  };
}

const closureExample = outerFunction("I'm from outer function!");

// The inner function is now executed separately, but still remembers the outer function's variable
closureExample("I'm from inner function!");

// Output
Outer Variable: I'm from outer function!
Inner Variable: I'm from inner function!

```

## What are the function types?

**Anonymous Function**

A function without names or unnamed functions is called an anonymous function
```
function () {
console.log("This is anonymous function");
}
```
**Named Function**
A function declared with a name is called a named function

```
function abc () {
  // TO DO Something in abc function (Function Declaration)
}


var abc = function () {
 // TO DO Something in abc function (Function Expression)
}

var abc = () => {
// TO DO Something in abc arrow function
}
```
**Function Declaration**
A function declaration is the traditional way of defining a function. It uses the function keyword followed by the function name, parameters, and the function body.
Function declarations are hoisted, meaning they are moved to the top of their scope before code execution starts. So you can call the function before it's declared in the code.

**Function Expression**
A function expression is when you assign a function to a variable. It can be anonymous or named, and the function is not hoisted.
Function expressions are not hoisted. The function definition is only available after the assignment, meaning you cannot call the function before it is defined.

**Arrow Functions**
An arrow function is a concise syntax for writing function expressions. It behaves similarly to function expressions in terms of hoisting and definition.

**HOCs Functions**

In JavaScript, Higher-Order Functions (HOCs) are functions that either:

Accept one or more functions as arguments, or Return a function as their result.
The idea behind HOCs is that they allow you to create more flexible and reusable functions by taking advantage of the ability to pass and return functions.

Accepting functions as arguments: HOCs can take one or more functions as input.
Returning a function: HOCs can return a new function, possibly with enhanced functionality.

Array methods like map, filter, and reduce are built-in higher-order functions because they take a callback function as an argument.

**Advantage:**

**Reusability**: HOCs make code more reusable by abstracting common behavior.

**Abstraction**: You can define generic functions that can be customized by passing in different callback functions.

**Modularity**: They help in breaking down complex logic into simpler, smaller units, making the code easier to maintain.


```
function withLogging(func) {
  return function(...args) {
    console.log('Function called with arguments:', args);
    const result = func(...args);
    console.log('Function result:', result);
    return result;
  };
}

function add(a, b) {
  return a + b;
}

const addWithLogging = withLogging(add);
addWithLogging(2, 3);

// Output: Function called with arguments: [2, 3]
// Output: Function result: 5

```

## What is the callback?

As we know, functions are first-class citizens in JavaScript, which means that functions can be assigned to variables, passed as arguments (parameters) to other functions, and returned from other functions. This feature is unique to JavaScript (and a few other languages), which is why functions are considered first-class citizens.

A callback function is a function that is passed as an argument to another function. The callback function is then invoked at a later point in time, often after some kind of event or operation has been completed. This is what makes it a callback.

```
function greeting(name, callback) {
  console.log("Hello, " + name);
  callback();  // The callback function is called here
}

function goodbye() {
  console.log("Goodbye!");
}

// Pass the 'goodbye' function as a callback to 'greeting'
greeting("Alice", goodbye);

```

## What is callback hell?

Callback hell (also known as Pyramid of Doom) is a term used to describe the situation in JavaScript where callbacks are nested within other callbacks, creating code that becomes deeply indented and hard to read, understand, and maintain. This usually happens when multiple asynchronous operations, like reading files, making API requests, or handling events, are chained together using callbacks.

Below is example for nested callback,  callback hell, inversion of control
 * createOrder
 * proceedPayment
 * orderSummery
 * updateWallet
 * Managing code is hard, pyramid of Doom, creating callback hell, and also losing control of code which raises inversion control

```

doSomething(function(err, result) {
  if (err) {
    console.log("Error:", err);
  } else {
    doSomethingElse(result, function(err, result2) {
      if (err) {
        console.log("Error:", err);
      } else {
        doYetAnotherThing(result2, function(err, result3) {
          if (err) {
            console.log("Error:", err);
          } else {
            // Continue processing
            console.log("Final Result:", result3);
          }
        });
      }
    });
  }
});
```

**Why does Callback Hell happen?**
When you have multiple asynchronous tasks that depend on one another, you often need to pass callbacks to handle the results of each task.
As each callback may also require another callback (for the next step in the process), the code can become deeply nested and harder to manage.

**Why is Callback Hell a Problem?**
Readability: As the number of nested callbacks increases, the code becomes harder to read and understand.
Maintainability: Adding more functionality can lead to more deeply nested callbacks, which makes future changes difficult and error-prone.
Error Handling: Handling errors in deeply nested callbacks can be tricky and lead to repetitive code.

## What is Promise?

A Promise is a JavaScript object that represents the eventual completion or failure of an asynchronous operation (such as I/O operations). A Promise can be in one of three states: pending, fulfilled, or rejected.

A Promise is created using the new Promise() constructor, which accepts a function called the executor. This function takes two parameters: resolve and reject. The resolve function is called when the asynchronous operation succeeds, while the reject function is called when it fails.

```
// Creating a Promise
let myPromise = new Promise(function(resolve, reject) {
  let success = true; // Change this to false to simulate failure
  
  if (success) {
    resolve("The operation was successful!");
  } else {
    reject("The operation failed.");
  }
});

// Consuming the Promise
myPromise
  .then(function(result) {
    console.log(result); // This will be called if the promise is resolved
  })
  .catch(function(error) {
    console.log(error); // This will be called if the promise is rejected
  });

// Using async/await to consume the Promise
async function executeOperation() {
  try {
    let result = await myPromise; // Await the Promise
    console.log(result); // This will be called if the promise is resolved
  } catch (error) {
    console.log(error); // This will be called if the promise is rejected
  }
}

executeOperation();

```

## What are promise APIs?
 
**Promise.all()** is used to execute multiple promises in parallel and wait for all of them to settle (either resolve or reject).

It takes an array of promises as an argument and returns a single promise that resolves when all promises in the array have resolved, or rejects if any one of them fails.

The result of Promise.all() is an array of results from all the promises, in the same order as the input array.

If any of the promises reject, Promise.all() immediately rejects with the reason of the first rejected promise, without waiting for other promises to settle.

**Key Points:**
All promises must resolve for the result to be returned.

If any promise rejects, the returned promise rejects immediately, and the error is thrown as the rejection value.

```
function resolveAfter(time, value) {
  return new Promise((resolve) => {
    setTimeout(() => resolve(value), time);
  });
}

function rejectAfter(time, reason) {
  return new Promise((_, reject) => {
    setTimeout(() => reject(reason), time);
  });
}

// Creating some promises to resolve and reject
const promise1 = resolveAfter(1000, 'v1');
const promise2 = resolveAfter(2000, 'v2');
const promise3 = rejectAfter(1500, 'Error in promise 3');
const promise4 = resolveAfter(3000, 'v4');

// Using Promise.all
Promise.all([promise1, promise2, promise3, promise4])
  .then((results) => {
    console.log("All promises resolved:", results);  // This won't run if any promise is rejected
  })
  .catch((error) => {
    console.log("Promise rejected with error:", error);  // This will run if any promise fails
  });

Note:
In this example, promise3 rejects after 1.5 seconds, so Promise.all() will immediately reject, and the remaining promises (promise1, promise2, promise4) are not waited for.
```

**Promise.allSettled()** is a method that waits for all promises to settle, regardless of whether they resolve (succeed) or reject (fail). Unlike Promise.all(), which rejects immediately if any promise fails, Promise.allSettled() ensures that all promises complete and provides an array of results, indicating whether each promise was resolved or rejected.

```

function resolveAfter(time, value) {
  return new Promise((resolve) => {
    setTimeout(() => resolve(value), time);
  });
}

function rejectAfter(time, reason) {
  return new Promise((_, reject) => {
    setTimeout(() => reject(reason), time);
  });
}

// Creating some promises to resolve and reject
const promise1 = resolveAfter(1000, 'v1');
const promise2 = resolveAfter(2000, 'v2');
const promise3 = rejectAfter(1500, 'Error in promise 3');
const promise4 = resolveAfter(3000, 'v4');

// Using Promise.allSettled
Promise.allSettled([promise1, promise2, promise3, promise4])
  .then((results) => {
    console.log("All promises settled:", results);
  });

//====Output 
All promises settled: [
  { status: "fulfilled", value: "v1" },
  { status: "fulfilled", value: "v2" },
  { status: "rejected", reason: "Error in promise 3" },
  { status: "fulfilled", value: "v4" }
]
```

**Promise.race()** is a method that waits for the first promise to settle (either fulfill or reject). As soon as one of the promises settles (either resolves or rejects), Promise.race() immediately settles with the result of that first settled promise. The remaining promises are ignored once the first one has settled.

**Promise.any()** is wait for the first settled promise with a successful value. If all promises are rejected, it returns an aggregated error.


## What is event loop in javascript?

JavaScript is a fascinating single-threaded, non-blocking, asynchronous, and concurrent language. If this sounds complex, don't worry! Let's break it down into simple terms by exploring the Event Loop, Call Stack, Microtask Queue, and Macrotask Queue.

**Call Stack:**

Imagine the call stack as a list where JavaScript keeps track of function calls. When you call a function, it gets added to the top of this list. Once the function finishes, itâ€™s removed. If a function calls another function, the new one gets added to the top, creating a stacking effect.

**Event Loop:**

The event loop is like a diligent coordinator, making sure everything runs smoothly. It watches over the call stack and task queues. If the call stack is empty, it checks the task queues and moves tasks to the call stack for execution. This helps keep your applications responsive and free from freezing.

**Microtask Queue:**

Microtasks are usually promises and mutation observers. When a promise resolves, its .then() callback goes to the microtask queue. Microtasks are the top priority. After finishing a task in the call stack, the event loop first handles all tasks in the microtask queue before moving to the macrotask queue, ensuring crucial operations are done quickly.

**Macrotask Queue:**

Macrotasks include timers (setTimeout, setInterval), I/O operations, and other events. These tasks go into the macrotask queue. The event loop processes them one by one in a first-in, first-out (FIFO) order, but only after the call stack and microtask queue are empty.

**How They Work Together:**

Call Stack Execution: Functions run one at a time.

Microtask Processing: After the call stack is empty, the event loop handles all microtasks.

Macrotask Processing: Once the microtask queue is empty, the event loop processes the next macrotask.

**Visualizing the Flow:**

Call Stack: Functions are added and removed like a stack of dishes.

Microtask Queue: Promises and other high-priority tasks are queued and executed first.

Macrotask Queue: Timers and other lower-priority tasks are queued and executed after microtasks.

![1721185522661](https://github.com/user-attachments/assets/fe7819d6-42a8-42b9-ac38-3bd46dbbd5c3)

## What is Debouncing & Throttling? 

Both are techniques to stop unnecessary API calls which will put a lot of pressure on the server (idea is to limit the frequency of function execution).

**Debouncing:**
On the Flipkart eCommerce website, when you type a product name like 'Notebook', a small delay of approximately 300ms is introduced between each keystroke before making the API call for suggestions. This prevents API calls for every individual keystroke and instead sends a request after the user has stopped typing for a brief moment.

Debouncing waits for a pause in activity before triggering an action.

**Throttling:**
On the Flipkart eCommerce website, when scrolling through the product listings, a request is sent to load more products at a fixed interval of 300ms. Even if the user scrolls continuously, the API call is made only once every 300ms, preventing excessive API calls during fast scrolling.

Throttling ensures the action is performed at regular intervals, regardless of how many times the event is triggered.

```
const debounce = (callback, del) => {
  let timer;
  return function (...args) {
    if (timer) clearTimeout(timer);
    timer = setTimeout(() => {
      callback(...args);
    }, del);
  };
};

function callMe() {
  console.log("Call Me");
}

const debounceCallme = debounce(callMe, 2000);
debounceCallme();
debounceCallme();
debounceCallme();
debounceCallme();


const throttling = function (cb, dl) {
  let lastTrigger = 0;
  return function () {
    const currTime = Date.now();

    if (currTime - lastTrigger < dl) return;
    lastTrigger = currTime;
    return cb();
  };
};

const throttlingCall = throttling(callMeThrotle, 10);

function callMeThrotle() {
  console.log("callMeThrotle");
}

throttlingCall();
throttlingCall();
throttlingCall();
throttlingCall();
```

## What is about call(), apply(), bind () ?

In JavaScript, call(), apply(), and bind() are methods used to invoke functions with a specified **this** value and **arguments**. **These methods are particularly useful when working with context and function borrowing**. They allow you to set the value of this in different contexts and pass arguments to a function dynamically.

**call()** is used to invoke a function with a specific **this** value and **arguments** passed individually (comma separated values ).
It immediately calls the function with the given this value and arguments.

**apply()** is very similar to call(), but instead of passing the arguments individually, you pass them as an array or array-like object. It is useful when you donâ€™t know the exact number of arguments to pass.

**bind()** is different from call() and apply() because it does not immediately invoke the function. Instead, it returns a new function with the specified **this** value and any pre-set arguments. This new function can be invoked later. It is particularly useful when you need to ensure a function retains a specific this value, even when it's executed in a different context.

```
function fullname(homeTwon, state) {
  console.log(
    this.firstName,
    " ",
    this.lastName,
    "From",
    homeTwon,
    "And State is",
    state
  );
}

const obj1 = {
  firstName: "Senthilkumar",
  lastName: "Karumbairam",
};

const obj2 = {
  firstName: "Sivakumar",
  lastName: "Karumbairam",
};

const obj3 = {
  firstName: "Suresh",
  lastName: "Karumbairam",
};

fullname.call(obj1, "Ariyalur", "Tamilnadu");
// apply
fullname.apply(obj2, ["Trichy", "Tamilnadu"]);
// bind
const callFullname = fullname.bind(obj3, "Pollachi", "Tamilnadu");
callFullname();

```
## Polifils of Function call, call(), apply(), bind()

```
Function.prototype.myCall = function (obj = {}, ...args) {
  if (typeof this !== "function") {
    throw new Error("Function is not Callable");
  }
  console.log("Custom Call Method");
  obj.fn = this;
  obj.fn(...args);
};

Function.prototype.myApply = function (obj = {}, args = []) {
  if (typeof this !== "function") {
    throw new Error("Function is not Callable");
  }

  if (!Array.isArray(args)) {
    throw new Error("Arguments are not iteratable");
  }

  console.log("Custom Apply Method");
  obj.fn = this;
  obj.fn(...args);
};

Function.prototype.myBind = function (obj = {}, ...args) {
  if (typeof this !== "function") {
    throw new Error("Function is not Callable");
  }
  obj.fn = this;
  return function (...newArgs) {
    console.log("Custom Bind Method");
    return obj.fn(...args, ...newArgs);
  };
};

fullname.myCall(obj1, "Ariyalur", "Tamilnadu");
fullname.myApply(obj1, ["Ariyalur", "Tamilnadu"]);
const myBind1 = fullname.myBind(obj1, "Ariyalur");
myBind1("India");

```

## Polifils of map(), filter(), reduce() Array methods.

```
Array.prototype.myMap = function (cb) {
  let tempResult = [];
  for (let i = 0; i < this.length; i++) {
    tempResult.push(cb(this[i], i, this));
  }
  return tempResult;
};

const testArray = [4, 5, 7];
const result = testArray.myMap((el, idx) => el * 5);

Array.prototype.myFilter = function (cb) {
  let tempResult = [];
  for (let i = 0; i < this.length; i++) {
    if (cb(this[i], i, this)) {
      tempResult.push(this[i]);
    }
  }
  return tempResult;
};

const resultFilter = testArray.myFilter((el, idx) => el > 4);

Array.prototype.myReduce = function (cb, intialValue) {
  let accum = intialValue;

  for (let i = 0; i < this.length; i++) {
    accum = accum ? cb(accum, this[i], i, this) : this[0];
  }

  return accum;
};

const testArray1 = [4, 5, 7];
const result3 = testArray1.myReduce((acc, ele, id, arr) => {
  return acc + ele;
}, 0);

```

## What is Event Delegation? 

Event delegation in JavaScript is a technique where you attach a single event listener to a parent element instead of adding individual event listeners to each child element. This technique is particularly useful for handling events on dynamically created or future elements, as well as for improving performance when dealing with a large number of child elements.

**Advantages:**

Efficient memory usage: Rather than attaching an event listener to every individual child element, only one listener is attached to the parent, which saves memory and reduces overhead.

Works with dynamic elements: If new child elements are added to the DOM after the initial page load (e.g., via JavaScript), they will still trigger the event because the listener is on the parent element, not the child.

Improved performance: It reduces the number of event listeners attached to elements, which can improve performance, especially with many elements.
```
// HTML
<ul id="parent">
  <li class="child">Item 1</li>
  <li class="child">Item 2</li>
  <li class="child">Item 3</li>
</ul>

//JS
// Select the parent element
const parent = document.getElementById('parent');

// Attach a single event listener to the parent element
parent.addEventListener('click', function(event) {
  // Check if the clicked element is a child <li> element
  if (event.target && event.target.matches('li.child')) {
    console.log('Item clicked:', event.target.textContent);
  }
});
```

## Describe the async and defer attributes in the script tag.

![wfL82](https://github.com/user-attachments/assets/ce94cf85-bd7d-4adc-b7af-5ee3d1b39879)

## what is parameters, arguments & rest operators?

- Parameters: Variable in the function's declaration param1, param2
  
       ```
        function ABC(param1, param2 ){
         console.log(arguments); // Arguments object
         console.log(param1, param2);
        }
      
       ABC("Test Argument1", "Test Argument2");
      ```
- Arguments: Arguments are the values which received by the function or while executing ABC("Test Argument1", "Test Argument2")
  
    - Array-like object containing all function arguments.
    -  Not a real array (no .map(), .filter(), etc.)
    -  Available in regular functions (not arrow functions).
    -  Not available in arrow functions (this binding issues).
    -  Cannot use with default or named parameters.
    -  ```
       function sum() {
          console.log(arguments); // Arguments object
          return Array.from(arguments).reduce((acc, num) => acc + num, 0);
        }
        
        console.log(sum(1, 2, 3, 4)); // âœ… 10

       ```
  
- rest Operators: If we are passing more than one variables (Params) in the functinons declration we can simply pass (3 dots) function (...numbers) {}
  
   -  Works in both regular and arrow functions.
   -  Real array (has .map(), .reduce(), etc.).
   -  Can be used with named parameters.
   -  ```
      function sum(...numbers) {
        console.log(numbers); // Real array
        return numbers.reduce((acc, num) => acc + num, 0);
      }
      
      console.log(sum(1, 2, 3, 4)); // âœ… 10

      ```

## What are the performance factors of applications?

**Genaral Optimization:**

- ðŸ”¹ Minify & Compress Files â†’ Use Gzip/Brotli
- ðŸ”¹ Use a CDN â†’ Distribute static files globally
- ðŸ”¹ Reduce HTTP Requests â†’ Combine CSS/JS files
- ðŸ”¹ Prefetch & Preload Resources â†’ Load assets efficiently
- ðŸ”¹ Enable Browser Caching â†’ Store static resources locally

**Front End (Client Side Optimization)**

- ðŸ”¹ Code Splitting & Lazy Loading â†’ Load only required components (React.lazy())
- ðŸ”¹ Optimize Images â†’ Use WebP, AVIF, SVG, Lazy Load
- ðŸ”¹ Reduce CSS & JS Size â†’ Minify & remove unused CSS (PurgeCSS)
- ðŸ”¹ Use Efficient CSS & JS â†’ Avoid heavy libraries, use vanilla JS when possible
- ðŸ”¹ Optimize Rendering Performance â†’ Avoid unnecessary re-renders (useMemo, useCallback, React.memo)
- ðŸ”¹ Use Progressive Web App (PWA) â†’ Enable offline support with Service Workers
- ðŸ”¹ Improve Core Web Vitals â†’ Optimize LCP, FID, CLS

**Backend Optimization (Server-Side)**

- ðŸ”¹ Use Caching (Redis, Memcached) â†’ Reduce redundant requests
- ðŸ”¹ Optimize Database Queries â†’ Use indexes, avoid N+1 queries
- ðŸ”¹ Reduce Server Response Time â†’ Optimize API logic, use background jobs
- ðŸ”¹ Enable HTTP/2 & HTTP/3 â†’ Faster request handling
- ðŸ”¹ Use Asynchronous Processing â†’ Offload heavy tasks to workers
- ðŸ”¹ Compress API Responses (Gzip/Brotli) â†’ Reduce payload size
- ðŸ”¹ Use Rate Limiting & Load Balancers â†’ Prevent DDoS & improve availability

**Database Optimization**

- ðŸ”¹ Use Indexing â†’ Speed up searches
- ðŸ”¹ Normalize & Denormalize Data Where Needed â†’ Reduce joins & improve query performance
- ðŸ”¹ Optimize Queries â†’ Avoid SELECT *, fetch only required fields
- ðŸ”¹ Use Connection Pooling â†’ Reduce connection overhead
- ðŸ”¹ Implement Read/Write Replicas â†’ Improve scalability

 **Network & Security Optimization**

- ðŸ”¹ Use HTTPS & Secure Headers â†’ Prevent attacks
- ðŸ”¹ Enable Content Security Policy (CSP) â†’ Prevent XSS attacks
- ðŸ”¹ Implement DDoS Protection â†’ Use rate limiting & firewall rules
- ðŸ”¹ Optimize API Calls â†’ Debounce & throttle unnecessary requests
- ðŸ”¹ Use WebSockets for Real-time Updates â†’ Reduce polling overhead

### React Profilor 

React Profiler is a tool provided within React DevTools that helps analyze the performance of your React application. It allows you to measure the rendering time of each component, track unnecessary re-renders, and identify performance bottlenecks at the component level.

Key benefits:

- Measure render times: See how long each component takes to render, helping you spot inefficient components.
- Optimize performance: By identifying which components are slow or re-rendering unnecessarily, you can focus on optimizing those areas.
- Track re-renders: Understand why a component re-renders (e.g., due to state changes, prop updates), helping to reduce unnecessary re-renders.

How to use:

- Open React DevTools in your browser.
- Navigate to the Profiler tab.
- Start recording while interacting with your app.
- View the component render times, re-renders, and other performance details.
- This tool is specifically useful when optimizing complex apps where performance at the component level matters.

### SSR (Server-Side Rendering) vs. CSR (Client-Side Rendering)

When deciding between SSR and CSR, it's important to consider the specific needs of your application:

**CSR (Client-Side Rendering):** If the website is rich in user interactions after the initial load, and SEO is not a major concern (e.g., single-page apps or applications that are not content-heavy), CSR is often the better choice. It provides a faster, more dynamic user experience once the JavaScript is loaded, but SEO may be less optimized.

**SSR (Server-Side Rendering):** If SEO and initial load time are crucial (for content-heavy websites or those requiring better indexing by search engines), SSR is typically preferred. It renders the content on the server and sends a fully rendered page to the client, improving SEO and reducing time to content.

**Hybrid Approach:** In some cases, a hybrid approach can be beneficial, where critical content is rendered server-side for SEO and faster initial load, and dynamic parts of the site are rendered client-side for better interactivity. Technologies like Next.js or Nuxt.js support this hybrid approach.

### Code Splitting 

Code splitting is a technique in web development that breaks up large JavaScript files into smaller, more manageable chunks. This improves the initial loading time of a web page by loading only the necessary code upfront, while the rest of the code is loaded as needed (on-demand).

With code splitting, parts of the application that arenâ€™t immediately needed (like components not visible or not used on the current page) are split into separate bundles, and they are loaded only when the user interacts with them.

Benefits:

- Improved initial load time: Reduces the size of the initial JavaScript file that the browser needs to download.
- On-demand loading: Lazy-load components and resources only when required, making the site feel faster and more responsive.
- Better performance: Smaller bundle sizes lead to faster parsing and execution of JavaScript.
```
import React, { Suspense } from 'react';

// Lazy load the component
const MyComponent = React.lazy(() => import('./MyComponent'));

const App = () => (
  <Suspense fallback={<div>Loading...</div>}>
    <MyComponent />
  </Suspense>
);

```

### Error Boundaries in React:
- React Error Boundaries are components that help catch JavaScript errors anywhere in a component tree and log those errors, and optionally display a fallback UI to the user.
- You can use the react-error-boundary library for this purpose, but React's built-in error boundaries do not require an external library.

### The Core Web Vitals are:

- Gives a better user experience
- Best SEO ranking
- Standardize performance matrices 

**Largest Contentful Paint (LCP)**: Measures loading performance. It tracks the time it takes for the largest visible content (like an image or text block) to load.
Good score: < 2.5 seconds

**First Input Delay (FID):** Measures interactivity. It tracks the time from when a user first interacts with the page (clicking a button or link) to when the browser responds.
Good score: < 100 ms

**INP (Interaction to Next Paint)** What it measures: INP tracks the time from when a user interacts with the page (similar to FID) to the next visible change on the screen after that interaction (such as rendering new content, or updating the UI).

Why it matters: It offers a more comprehensive measure of interactivity because it captures how quickly the page responds and reflects the change after user input.

Good score: INP should be less than 200 milliseconds for optimal performance.

**Cumulative Layout Shift (CLS):** Measures visual stability. It tracks how much the page layout shifts during loading, affecting user experience.
Good score: < 0.1
Example: A webpage that loads slowly (high LCP), takes a long time to respond to user interactions (high FID), and has content that shifts around (high CLS) will have poor Core Web Vitals scores, indicating a poor user experience.

### Virtualization 

Virtualization in React is a technique used to efficiently render large lists or collections of items by only rendering the visible portion of the list, instead of rendering the entire list at once. This reduces memory usage and improves performance, especially for long or infinite scrollable lists.

Improved performance: By rendering only a small number of items, the browser uses less memory and can render faster.
Reduced rendering time: The number of DOM nodes is minimized, leading to faster updates and reduced layout recalculations.

```
import { FixedSizeList as List } from 'react-window';

const MyList = () => {
  const items = Array.from({ length: 1000 }, (_, index) => `Item ${index + 1}`);

  const Post = ({index}) => {
    
  }
  return (
    <List
      height={400} // Visible height of the list
      itemCount={items.length} // Total number of items
      itemSize={35} // Height of each item
      width={300} // Width of the list
    >
      {({ index, style }) => (
        <div style={style}>{items[index]}</div>
      )}
    </List>
  );
};

```

### Accessibility 

Web Accessibility (a11y) is the practice of ensuring that websites and web applications are usable by all people, including those with disabilities. This includes users with visual, auditory, motor, or cognitive impairments. Accessible websites provide alternative methods of interaction, so users can access content and functionality using various tools and assistive technologies (e.g., screen readers, voice recognition software).

**Key Principles of Web Accessibility:**

- Perceivable: Information and user interface components must be presented in ways that users can perceive. For example, text should have sufficient contrast, and images should have alt text for screen readers.
- Operable: The interface must be operable by all users. For example, forms should be navigable via the keyboard, and buttons should be accessible via both mouse and keyboard.
- Understandable: Information and the operation of the user interface must be understandable. For example, clear instructions should be provided, and content should be structured logically.
- Robust: Content must be robust enough to work with current and future technologies, including assistive technologies.

**How to Check Web Accessibility:**

You can check web accessibility manually or use tools to help automate the process. Here are some common methods:

**Manual Testing:**

- Keyboard Navigation: Ensure all interactive elements can be navigated using only the keyboard (e.g., tabbing through form fields, buttons, etc.).
- Screen Reader: Use screen reader software (e.g., NVDA, VoiceOver) to check if all content is read out and correctly structured.
- Color Contrast: Ensure there is sufficient contrast between text and background, using tools like the WCAG Contrast Checker.

**Automated Tools:**

Lighthouse (built into Chrome DevTools):
  - Open the DevTools (F12) â†’ Go to the Lighthouse tab â†’ Select "Accessibility" and click "Generate Report."
  -`It gives a score for accessibility and suggests improvements.
- axe Accessibility Checker: A browser extension that checks for accessibility issues and provides detailed reports on how to fix them.
- WAVE (Web Accessibility Evaluation Tool): An online tool that analyzes web pages for accessibility issues and offers suggestions.
- React A11y: For React applications, this tool provides linting rules to catch accessibility issues during development.

**Conclusion:**
Web accessibility ensures everyone, regardless of ability, can access and interact with web content. By using tools like Lighthouse, axe, and following WCAG guidelines, you can make sure your website is accessible and provides a better experience for all users.

### Image Optimization
- What it is: Compress and serve images in formats that are optimized for the web (e.g., WebP, AVIF).
- How to implement: Use image compression tools like ImageOptim, TinyPNG, or Squoosh; implement responsive image sizes (srcset) for various screen resolutions.
- Benefit: Reduces image file size and loading times without sacrificing quality.

### Minimize HTTP Requests

- What it is: Reduce the number of requests made by the browser.

- How to implement:

 - Combine CSS and JavaScript files.
 - Use SVG sprites for icons.
 - Inline small assets (e.g., small images, CSS) directly in HTML using Base64.
- Benefit: Reduces the amount of data transferred and speeds up the page load time.

### Use Content Delivery Networks (CDN)

- What it is: Distribute your static assets (images, CSS, JS) across a global network of servers.
- How to implement: Use CDNs like Cloudflare, AWS CloudFront, or Fastly.
- Benefit: Reduces latency by serving content from a server closer to the user.

### Asynchronous Loading for Scripts

- What it is: Load JavaScript files asynchronously to avoid blocking page rendering.
- How to implement: Use the async or defer attribute for external JavaScript files.
- Benefit: Ensures the page content loads without waiting for scripts to finish.

### Caching Resources 

- What it is: Cache resources to avoid fetching the same data repeatedly.
- How to implement: Use Service Workers, set proper Cache-Control headers, and implement browser caching strategies.
- Benefit: Reduces repeated network requests and makes your site faster by serving assets from the cache.

### Prefetch and Preload Resources

- What it is: Load resources like fonts or images in advance so they're available when needed.
- Preload makes the browser start fetching resources early (before the browser needs it) to ensure they're ready when needed.
- It is used for critical resources that are required early in the page load.
- Preload is often used for scripts, styles, fonts, or images that are needed in the next part of the page.
- ```
  <link rel="preload" href="critical-style.css" as="style">
  <script rel="preload" href="critical-script.js" as="script"></script>
  ```
- Prefetch is used for resources that are likely to be needed in the future, often for subsequent pages or interactions.
- It has a lower priority than preload, so it doesn't interfere with the current page rendering.
- Prefetch is typically used for resources related to the next possible page the user might visit (e.g., JavaScript files, images for next page).
- ```
  <link rel="prefetch" href="next-page.js">
  ```
**Example Use Case Scenario:**

Imagine a single-page app (SPA) with multiple sections:

- The homepage (current page) needs a critical script for rendering above-the-fold content. Use preload for that script.
- When the user scrolls to a new section or clicks a button to load additional content, you know that the resources for that section will be needed shortly. Use prefetch to fetch the necessary resources in advance.

### Web Workers:

Web Workers are a feature of web browsers that allow you to run JavaScript code in the background, outside the main browser thread. This helps prevent performance bottlenecks that occur when long-running tasks block the UI thread, making the application slow or unresponsive. In simple terms, Web Workers allow you to run JavaScript tasks in parallel, without affecting the user interface's smoothness or responsiveness.

**How Web Workers Work:**

- Main Thread (UI Thread): This is where the regular JavaScript code runs and interacts with the DOM, updating the user interface.
- Worker Thread: This is a separate thread created by the main thread where you can offload heavy, non-UI tasks (like complex calculations or data processing).
- The key advantage is that Web Workers allow your web application to stay responsive while performing intensive operations, like processing large amounts of data or performing computations.
- Non-blocking: The main UI thread is not blocked by long-running tasks. The user can continue interacting with the web page while the background work happens in the worker.
- Separate Environment: Web Workers run in their own isolated thread and do not have access to the DOM directly. They can only communicate with the main thread through a messaging system.
- Multithreading: Web Workers allow you to run JavaScript in parallel, taking advantage of multiple cores in modern CPUs for better performance.

**How to Create a Web Worker:**

Creating a Simple Worker, main.js (main thread, where the UI runs):

```
// Create a new Web Worker instance and link to the worker script.
const worker = new Worker('worker.js');

// Send a message to the worker to start a task.
worker.postMessage('Start processing');

// Listen for messages from the worker (results, updates, etc.)
worker.onmessage = function (event) {
    console.log('Result from worker: ', event.data);
};

// Handle any errors in the worker.
worker.onerror = function (error) {
    console.error('Error in worker: ', error.message);
};

```

worker.js (worker thread):

```
// The worker receives a message from the main thread.
onmessage = function (event) {
    if (event.data === 'Start processing') {
        // Simulating a heavy computational task
        let result = 0;
        for (let i = 0; i < 1e9; i++) {
            result += i;
        }
        
        // Send the result back to the main thread.
        postMessage(result);
    }
};
```
**Limitations:**

- No DOM Access: Web Workers run in a separate thread and cannot directly access or modify the DOM. They are restricted to JavaScript execution, which ensures that UI updates are not blocked.
- Communication Overhead: The communication between the main thread and workers occurs through message-passing (i.e., postMessage). This can introduce some overhead, especially if large amounts of data are passed frequently.
- Browser Support: While most modern browsers support Web Workers, older browsers (e.g., Internet Explorer) may not fully support them.

**Conclusion:**

Web Workers are an excellent tool for performing computationally expensive or time-consuming tasks in the background, without affecting the user experience. They enable better performance by utilizing multithreading, ensuring the main UI thread stays responsive. By offloading tasks such as data processing, sorting, and complex computations, Web Workers allow for faster, more efficient web applications.

## What are the security concern of an web application

Security is a critical concern in web application development. Web applications often deal with sensitive data, including personal information, payment details, and authentication credentials. If security is not properly managed, web applications can be vulnerable to various types of attacks that could compromise the application, its users, or both. Here are some key security concerns and risks associated with web applications:

1. Cross-Site Scripting (XSS)
   - What it is: XSS occurs when an attacker injects malicious scripts into web pages viewed by users. The injected script executes in the context of the victim's browser, potentially allowing the attacker to steal cookies, session tokens, or perform malicious actions on behalf of the user.
   - Mitigation:
     - Validate and sanitize user inputs
     - Use Content Security Policy (CSP) to prevent the execution of unauthorized scripts.
     - Escape any dynamic content that is rendered on the page.

2. Cross-Site Request Forgery (CSRF)
   - What it is: CSRF tricks the user into making an unwanted request to a web application where the user is authenticated. The attacker exploits the user's session to perform actions without their consent.
   - Mitigation:
     - Use anti-CSRF tokens in forms and requests to ensure they are legitimate.
     - Validate requests and ensure they originate from trusted sources.
     - Ensure that state-changing requests are made with POST rather than GET.
3. SQL Injection
   - What it is: SQL Injection occurs when an attacker inserts or manipulates SQL queries by inserting malicious code into user input fields. This can lead to unauthorized access to the database, data leakage, and even complete control over the database.
   - Mitigation:
     - Use prepared statements and parameterized queries to prevent malicious SQL code from being executed.
     - Avoid dynamic SQL queries and sanitize user input properly.
     - Limit the database privileges of the application account to reduce potential damage.
4. Denial of Service (DoS) & Distributed Denial of Service (DDoS)
   - What it is: DoS and DDoS attacks aim to overwhelm the server with a flood of requests, making the application or service unavailable to legitimate users.
   - Mitigation:
     - Use a Web Application Firewall (WAF) to filter malicious traffic.
     - Implement rate limiting, traffic throttling, and CAPTCHAs to prevent automated attacks.
     - Use DDoS protection services like Cloudflare, AWS Shield, or Akamai to absorb traffic surges.
